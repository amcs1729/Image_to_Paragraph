{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.2 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "! pip install -q pyyaml h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import RNN\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "import gc\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "glove_dir = '../input/glove/glove.6B.200d.txt'\n",
    "embeddings_index = {} # empty dictionary\n",
    "f = open(glove_dir, encoding=\"utf-8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def clean_captions(caption_list):\n",
    "        table = str.maketrans('', '', string.punctuation)\n",
    " \n",
    "        for i in range(len(caption_list)):\n",
    "                desc = caption_list[i]\n",
    "                # tokenize\n",
    "                desc = desc.split()\n",
    "                # convert to lower case\n",
    "                desc = [word.lower() for word in desc]\n",
    "                # remove punctuation from each token\n",
    "                desc = [w.translate(table) for w in desc]\n",
    "                # remove hanging 's' and 'a'\n",
    "                desc = [word for word in desc if len(word)>1]\n",
    "                # remove tokens with numbers in them\n",
    "                desc = [word for word in desc if word.isalpha()]\n",
    "                # store as string\n",
    "                caption_list[i] =  ' '.join(desc)\n",
    " \n",
    "        return (caption_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, 'r')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_filename = '../input/text-data/1342-0 (1).txt'\n",
    "doc = load_doc(in_filename)\n",
    "lines = doc.split('\\n')\n",
    "lines = clean_captions(lines)\n",
    "lines = lines[0: round((len(lines)/5))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25395/25395 [00:00<00:00, 906165.78it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_new= []\n",
    "for i in tqdm(range(len(lines))):\n",
    "  if (lines[i] != ''):\n",
    "    lines_new.append(lines[i])\n",
    "lines = lines_new\n",
    "del lines_new\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list()\n",
    "for i, key  in enumerate(lines):\n",
    "    word_list = (lines[i].split(' '))\n",
    "    for word in word_list:\n",
    " \n",
    "      words.append(word)\n",
    "vocabulary = set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ixtoword = {}\n",
    "wordtoix = {}\n",
    "ix = 1\n",
    "for w in list(vocabulary):\n",
    "    wordtoix[w] = ix\n",
    "    ixtoword[ix] = w\n",
    "    ix += 1\n",
    "\n",
    "ixtoword[0] = '<unk>'\n",
    "wordtoix['<unk>'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_length_caption(caption , max_len=50):\n",
    " \n",
    "    '''\n",
    "    Takes caption as input and makes them of equal length\n",
    "    \n",
    "    Parameters:-\n",
    "    caption (list) - The list of embedded caption to be made of particular length\n",
    "    max_len (int) - The max length of the caption\n",
    "    \n",
    "    Return type:-\n",
    "    \n",
    "    caption (list) :- Returns a list with zero padding of length = max_len\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    if(len(caption) == max_len):\n",
    "        return (caption)\n",
    "    else:\n",
    "        for i in range((max_len-len(caption))):\n",
    "            caption.append(0)\n",
    "    return caption\n",
    "def word_to_ix(caption , vocab):\n",
    "    '''\n",
    "    Maps the words to integers according to custom vocabulary\n",
    "    \n",
    "    Parameters:-\n",
    "    caption (list) - The caption to be embedded\n",
    "    vocab (dict) - The custom mapping that wil be used as vocabulary\n",
    "    \n",
    "    Return type:-\n",
    "    \n",
    "    caption (list) :- Returns a list after mapping them according to 'vocab'\n",
    "    '''\n",
    "        \n",
    "    transformed_caption=[]\n",
    "    for word in caption:\n",
    "        if (word in wordtoix.keys()):\n",
    "            transformed_caption.append(wordtoix[word])\n",
    "        else:\n",
    "            transformed_caption.append(wordtoix['<unk>'])\n",
    "    return (transformed_caption)\n",
    "        \n",
    "def ix_to_word(caption , vocab):\n",
    "    '''\n",
    "    Takes caption as input and maps them to words as defined by 'vocab'\n",
    "    \n",
    "    Parameters:-\n",
    "    caption (list) - The list of embedded caption to be made of particular length\n",
    "    vocab (dict) - The dictionary that wil be used as mapping\n",
    "    \n",
    "    Return type:-\n",
    "    \n",
    "    caption (list) :- Returns a list after converting respective integers to words according to vocab\n",
    "    '''\n",
    "    \n",
    "    transformed_caption=[]\n",
    "    for word in caption:\n",
    "        transformed_caption.append(ixtoword[word])\n",
    "\n",
    "    return (transformed_caption)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#words = list()\n",
    "#for i, key  in enumerate(lines):\n",
    "#    word_list = (lines[i].split(' '))\n",
    "#    for word in word_list:\n",
    " \n",
    "#      words.append(word)\n",
    "#vocabulary = set(words)\n",
    "\n",
    "#from collections import Counter \n",
    "  \n",
    "#def removeElements(lst, k): \n",
    "#    counted = Counter(lst) \n",
    "#    return [el for el in lst if counted[el] >= k] \n",
    " \n",
    "#k = 8\n",
    "#vocabulary_new = ((removeElements(flat_list, k))) \n",
    "#vocabulary_new = set(vocabulary_new)\n",
    "#vocabulary.update(['<unk>'])\n",
    "\n",
    "\n",
    "train_len = 12+1\n",
    "text_sequences = []\n",
    "for i in range(train_len,len(words)):\n",
    "    seq = words[i-train_len:i]\n",
    "    text_sequences.append(seq)\n",
    "\n",
    "\n",
    "def generator(batch_size=32):\n",
    "    \"\"\"\n",
    "    Yields the next training batch.\n",
    "    Suppose `samples` is an array [[image1_filename,label1], [image2_filename,label2],...].\n",
    "    \"\"\"\n",
    "    num_samples = len(text_sequences)\n",
    "    \n",
    "    while True:\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = text_sequences[offset:offset+batch_size]\n",
    " \n",
    "            input_seq=[]\n",
    "            output_seq=[]\n",
    " \n",
    "            for batch_sample in batch_samples:\n",
    " \n",
    " \n",
    "                #caption_text = batch_samples.at[batch_sample , 'image_caption']\n",
    "                #caption = caption_text.split()\n",
    "                batch_sample = word_to_ix(batch_sample , wordtoix)\n",
    "                #caption = same_length_caption(caption , max_len = 34)\n",
    " \n",
    "                #print(type(batch_sample))\n",
    "                #print(len(batch_sample))\n",
    "                \n",
    "                \n",
    "                #samples = word_to_ix(samples , wordtoix)\n",
    " \n",
    "                input_seq.append(np.array(batch_sample[0:-1]))\n",
    "                output_seq.append(np.array(batch_sample[-1:]))\n",
    " \n",
    "                #print(input_seq)\n",
    "                #print(output_seq)\n",
    "            \n",
    "            input_seq = np.array(input_seq)\n",
    "            output_seq = np.array(output_seq)\n",
    " \n",
    "            yield(input_seq , output_seq)\n",
    "  \n",
    "vocab_size = len(vocabulary) + 1\n",
    "embedding_dim = 200\n",
    "# Get 200-dim dense vector for each of the 10000 words in out vocabulary\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, i in wordtoix.items():\n",
    "    #if i < max_words:\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in the embedding index will be all zeros\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "\n",
    "  inputs1 = tf.keras.layers.Input(shape=(12))\n",
    "  se1 = tf.keras.layers.Embedding(input_dim = vocab_size, output_dim = embedding_dim)(inputs1)\n",
    "  se2 = tf.keras.layers.GRU(512,return_sequences=True )(se1)\n",
    "  se3 = tf.keras.layers.GRU(512,return_sequences=False )(se2)\n",
    "\n",
    "  output = tf.keras.layers.Dense(vocab_size,activation='softmax')(se3)\n",
    "\n",
    "  model = tf.keras.Model(inputs=[inputs1],outputs=[output])\n",
    "  opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "  model.compile(loss= 'sparse_categorical_crossentropy', optimizer=opt)\n",
    "\n",
    "  return model\n",
    "\n",
    "\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "#opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "#model.compile(loss= tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), optimizer=opt , metrics= ['accuracy'])\n",
    "\n",
    "model.layers[1].set_weights([embedding_matrix])\n",
    "model.layers[1].trainable = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_red = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='loss', factor=0.2, patience=3, verbose=1, mode='auto',\n",
    "    min_delta=0.0001, cooldown=0, min_lr=0.0000001)\n",
    "callbacks = [lr_red ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(batch_size= BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.backend import manual_variable_initialization\n",
    "manual_variable_initialization(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "106/105 [==============================] - 12s 115ms/step - loss: 0.2099 - lr: 8.0000e-05\n",
      "Epoch 2/200\n",
      "106/105 [==============================] - 12s 117ms/step - loss: 0.2079 - lr: 8.0000e-05\n",
      "Epoch 3/200\n",
      "106/105 [==============================] - 12s 111ms/step - loss: 0.2063 - lr: 8.0000e-05\n",
      "Epoch 4/200\n",
      "106/105 [==============================] - 12s 112ms/step - loss: 0.2044 - lr: 8.0000e-05\n",
      "Epoch 5/200\n",
      "106/105 [==============================] - 12s 111ms/step - loss: 0.2024 - lr: 8.0000e-05\n",
      "Epoch 6/200\n",
      "106/105 [==============================] - 12s 114ms/step - loss: 0.2008 - lr: 8.0000e-05\n",
      "Epoch 7/200\n",
      "106/105 [==============================] - 12s 115ms/step - loss: 0.1993 - lr: 8.0000e-05\n",
      "Epoch 8/200\n",
      "106/105 [==============================] - 12s 111ms/step - loss: 0.1974 - lr: 8.0000e-05\n",
      "Epoch 9/200\n",
      "106/105 [==============================] - 12s 111ms/step - loss: 0.1956 - lr: 8.0000e-05\n",
      "Epoch 10/200\n",
      "106/105 [==============================] - 12s 113ms/step - loss: 0.1944 - lr: 8.0000e-05\n",
      "Epoch 11/200\n",
      "106/105 [==============================] - 12s 115ms/step - loss: 0.1925 - lr: 8.0000e-05\n",
      "Epoch 12/200\n",
      "106/105 [==============================] - 12s 116ms/step - loss: 0.1907 - lr: 8.0000e-05\n",
      "Epoch 13/200\n",
      "106/105 [==============================] - 12s 112ms/step - loss: 0.1900 - lr: 8.0000e-05\n",
      "Epoch 14/200\n",
      "106/105 [==============================] - 12s 113ms/step - loss: 0.1879 - lr: 8.0000e-05\n",
      "Epoch 15/200\n",
      "106/105 [==============================] - 12s 112ms/step - loss: 0.1864 - lr: 8.0000e-05\n",
      "Epoch 16/200\n",
      "106/105 [==============================] - 12s 117ms/step - loss: 0.1846 - lr: 8.0000e-05\n",
      "Epoch 17/200\n",
      "106/105 [==============================] - 12s 113ms/step - loss: 0.1830 - lr: 8.0000e-05\n",
      "Epoch 18/200\n",
      "106/105 [==============================] - 12s 112ms/step - loss: 0.1811 - lr: 8.0000e-05\n",
      "Epoch 19/200\n",
      "106/105 [==============================] - 12s 111ms/step - loss: 0.1795 - lr: 8.0000e-05\n",
      "Epoch 20/200\n",
      "106/105 [==============================] - 12s 112ms/step - loss: 0.1782 - lr: 8.0000e-05\n",
      "Epoch 21/200\n",
      "106/105 [==============================] - 12s 117ms/step - loss: 0.1765 - lr: 8.0000e-05\n",
      "Epoch 22/200\n",
      "106/105 [==============================] - 12s 114ms/step - loss: 0.1755 - lr: 8.0000e-05\n",
      "Epoch 23/200\n",
      "106/105 [==============================] - 12s 113ms/step - loss: 0.1741 - lr: 8.0000e-05\n",
      "Epoch 24/200\n",
      "106/105 [==============================] - 12s 111ms/step - loss: 0.1723 - lr: 8.0000e-05\n",
      "Epoch 25/200\n",
      "106/105 [==============================] - 12s 113ms/step - loss: 0.1706 - lr: 8.0000e-05\n",
      "Epoch 26/200\n",
      "106/105 [==============================] - 12s 115ms/step - loss: 0.1690 - lr: 8.0000e-05\n",
      "Epoch 27/200\n",
      "106/105 [==============================] - 12s 111ms/step - loss: 0.1679 - lr: 8.0000e-05\n",
      "Epoch 28/200\n",
      "106/105 [==============================] - 12s 111ms/step - loss: 0.1664 - lr: 8.0000e-05\n",
      "Epoch 29/200\n",
      "106/105 [==============================] - 12s 110ms/step - loss: 0.1649 - lr: 8.0000e-05\n",
      "Epoch 30/200\n",
      "106/105 [==============================] - 12s 112ms/step - loss: 0.1638 - lr: 8.0000e-05\n",
      "Epoch 31/200\n",
      "106/105 [==============================] - 12s 115ms/step - loss: 0.1625 - lr: 8.0000e-05\n",
      "Epoch 32/200\n",
      "106/105 [==============================] - 12s 113ms/step - loss: 0.1614 - lr: 8.0000e-05\n",
      "Epoch 33/200\n",
      "106/105 [==============================] - 12s 111ms/step - loss: 0.1599 - lr: 8.0000e-05\n",
      "Epoch 34/200\n",
      "106/105 [==============================] - 12s 111ms/step - loss: 0.1586 - lr: 8.0000e-05\n",
      "Epoch 35/200\n",
      "106/105 [==============================] - 12s 111ms/step - loss: 0.1579 - lr: 8.0000e-05\n",
      "Epoch 36/200\n",
      "106/105 [==============================] - 12s 114ms/step - loss: 0.1564 - lr: 8.0000e-05\n",
      "Epoch 37/200\n",
      "106/105 [==============================] - 12s 112ms/step - loss: 0.1556 - lr: 8.0000e-05\n",
      "Epoch 38/200\n",
      "106/105 [==============================] - 12s 112ms/step - loss: 0.1535 - lr: 8.0000e-05\n",
      "Epoch 39/200\n",
      "106/105 [==============================] - 12s 111ms/step - loss: 0.1518 - lr: 8.0000e-05\n",
      "Epoch 40/200\n",
      "106/105 [==============================] - 12s 111ms/step - loss: 0.1506 - lr: 8.0000e-05\n",
      "Epoch 41/200\n",
      "106/105 [==============================] - 12s 116ms/step - loss: 0.1494 - lr: 8.0000e-05\n",
      "Epoch 42/200\n",
      "106/105 [==============================] - 12s 112ms/step - loss: 0.1480 - lr: 8.0000e-05\n",
      "Epoch 43/200\n",
      "106/105 [==============================] - 12s 110ms/step - loss: 0.1471 - lr: 8.0000e-05\n",
      "Epoch 44/200\n",
      "106/105 [==============================] - 12s 110ms/step - loss: 0.1460 - lr: 8.0000e-05\n",
      "Epoch 45/200\n",
      "106/105 [==============================] - 12s 110ms/step - loss: 0.1447 - lr: 8.0000e-05\n",
      "Epoch 46/200\n",
      "106/105 [==============================] - 12s 117ms/step - loss: 0.1433 - lr: 8.0000e-05\n",
      "Epoch 47/200\n",
      "106/105 [==============================] - 12s 112ms/step - loss: 0.1420 - lr: 8.0000e-05\n",
      "Epoch 48/200\n",
      "106/105 [==============================] - 12s 112ms/step - loss: 0.1406 - lr: 8.0000e-05\n",
      "Epoch 49/200\n",
      "106/105 [==============================] - 12s 111ms/step - loss: 0.1396 - lr: 8.0000e-05\n",
      "Epoch 50/200\n",
      "106/105 [==============================] - 12s 111ms/step - loss: 0.1383 - lr: 8.0000e-05\n",
      "Epoch 51/200\n",
      "106/105 [==============================] - 12s 117ms/step - loss: 0.1371 - lr: 8.0000e-05\n",
      "Epoch 52/200\n",
      "106/105 [==============================] - 12s 113ms/step - loss: 0.1360 - lr: 8.0000e-05\n",
      "Epoch 53/200\n",
      "106/105 [==============================] - 12s 111ms/step - loss: 0.1349 - lr: 8.0000e-05\n",
      "Epoch 54/200\n",
      "106/105 [==============================] - 12s 111ms/step - loss: 0.1338 - lr: 8.0000e-05\n",
      "Epoch 55/200\n",
      "106/105 [==============================] - 12s 110ms/step - loss: 0.1327 - lr: 8.0000e-05\n",
      "Epoch 56/200\n",
      "106/105 [==============================] - 12s 116ms/step - loss: 0.1317 - lr: 8.0000e-05\n",
      "Epoch 57/200\n",
      "106/105 [==============================] - 12s 111ms/step - loss: 0.1306 - lr: 8.0000e-05\n",
      "Epoch 58/200\n",
      "106/105 [==============================] - 12s 111ms/step - loss: 0.1296 - lr: 8.0000e-05\n",
      "Epoch 59/200\n",
      "106/105 [==============================] - 12s 111ms/step - loss: 0.1283 - lr: 8.0000e-05\n",
      "Epoch 60/200\n",
      "106/105 [==============================] - 12s 111ms/step - loss: 0.1273 - lr: 8.0000e-05\n",
      "Epoch 61/200\n",
      "106/105 [==============================] - 12s 117ms/step - loss: 0.1269 - lr: 8.0000e-05\n",
      "Epoch 62/200\n",
      "106/105 [==============================] - 12s 111ms/step - loss: 0.1260 - lr: 8.0000e-05\n",
      "Epoch 63/200\n",
      "106/105 [==============================] - 12s 110ms/step - loss: 0.1246 - lr: 8.0000e-05\n",
      "Epoch 64/200\n",
      "106/105 [==============================] - 12s 112ms/step - loss: 0.1235 - lr: 8.0000e-05\n",
      "Epoch 65/200\n",
      "106/105 [==============================] - 12s 112ms/step - loss: 0.1221 - lr: 8.0000e-05\n",
      "Epoch 66/200\n",
      "106/105 [==============================] - 12s 116ms/step - loss: 0.1208 - lr: 8.0000e-05\n",
      "Epoch 67/200\n",
      "106/105 [==============================] - 12s 112ms/step - loss: 0.1197 - lr: 8.0000e-05\n",
      "Epoch 68/200\n",
      "106/105 [==============================] - 12s 111ms/step - loss: 0.1186 - lr: 8.0000e-05\n",
      "Epoch 69/200\n",
      "106/105 [==============================] - 12s 112ms/step - loss: 0.1176 - lr: 8.0000e-05\n",
      "Epoch 70/200\n",
      "106/105 [==============================] - 12s 111ms/step - loss: 0.1168 - lr: 8.0000e-05\n",
      "Epoch 71/200\n",
      "106/105 [==============================] - 12s 115ms/step - loss: 0.1159 - lr: 8.0000e-05\n",
      "Epoch 72/200\n",
      "106/105 [==============================] - 12s 113ms/step - loss: 0.1151 - lr: 8.0000e-05\n",
      "Epoch 73/200\n",
      "106/105 [==============================] - 12s 111ms/step - loss: 0.1142 - lr: 8.0000e-05\n",
      "Epoch 74/200\n",
      "106/105 [==============================] - 12s 112ms/step - loss: 0.1134 - lr: 8.0000e-05\n",
      "Epoch 75/200\n",
      "106/105 [==============================] - 12s 112ms/step - loss: 0.1126 - lr: 8.0000e-05\n",
      "Epoch 76/200\n",
      "106/105 [==============================] - 12s 115ms/step - loss: 0.1115 - lr: 8.0000e-05\n",
      "Epoch 77/200\n",
      "106/105 [==============================] - 12s 112ms/step - loss: 0.1103 - lr: 8.0000e-05\n",
      "Epoch 78/200\n",
      "106/105 [==============================] - 12s 111ms/step - loss: 0.1093 - lr: 8.0000e-05\n",
      "Epoch 79/200\n",
      "106/105 [==============================] - 12s 111ms/step - loss: 0.1083 - lr: 8.0000e-05\n",
      "Epoch 80/200\n",
      "106/105 [==============================] - 12s 113ms/step - loss: 0.1073 - lr: 8.0000e-05\n",
      "Epoch 81/200\n",
      "106/105 [==============================] - 12s 114ms/step - loss: 0.1063 - lr: 8.0000e-05\n",
      "Epoch 82/200\n",
      "106/105 [==============================] - 12s 113ms/step - loss: 0.1055 - lr: 8.0000e-05\n",
      "Epoch 83/200\n",
      "106/105 [==============================] - 12s 111ms/step - loss: 0.1046 - lr: 8.0000e-05\n",
      "Epoch 84/200\n",
      "106/105 [==============================] - 12s 111ms/step - loss: 0.1038 - lr: 8.0000e-05\n",
      "Epoch 85/200\n",
      "106/105 [==============================] - 12s 112ms/step - loss: 0.1033 - lr: 8.0000e-05\n",
      "Epoch 86/200\n",
      "106/105 [==============================] - 12s 117ms/step - loss: 0.1030 - lr: 8.0000e-05\n",
      "Epoch 87/200\n",
      "106/105 [==============================] - 12s 113ms/step - loss: 0.1027 - lr: 8.0000e-05\n",
      "Epoch 88/200\n",
      "106/105 [==============================] - 12s 110ms/step - loss: 0.1012 - lr: 8.0000e-05\n",
      "Epoch 89/200\n",
      "106/105 [==============================] - 12s 111ms/step - loss: 0.0998 - lr: 8.0000e-05\n",
      "Epoch 90/200\n",
      "106/105 [==============================] - 12s 113ms/step - loss: 0.0987 - lr: 8.0000e-05\n",
      "Epoch 91/200\n",
      "106/105 [==============================] - 12s 115ms/step - loss: 0.0978 - lr: 8.0000e-05\n",
      "Epoch 92/200\n",
      "106/105 [==============================] - 12s 112ms/step - loss: 0.0969 - lr: 8.0000e-05\n",
      "Epoch 93/200\n",
      "106/105 [==============================] - 12s 111ms/step - loss: 0.0961 - lr: 8.0000e-05\n",
      "Epoch 94/200\n",
      "106/105 [==============================] - 12s 110ms/step - loss: 0.0953 - lr: 8.0000e-05\n",
      "Epoch 95/200\n",
      "106/105 [==============================] - 12s 111ms/step - loss: 0.0954 - lr: 8.0000e-05\n",
      "Epoch 96/200\n",
      "106/105 [==============================] - 12s 115ms/step - loss: 0.0950 - lr: 8.0000e-05\n",
      "Epoch 97/200\n",
      "106/105 [==============================] - 12s 112ms/step - loss: 0.0945 - lr: 8.0000e-05\n",
      "Epoch 98/200\n",
      "106/105 [==============================] - 12s 112ms/step - loss: 0.0933 - lr: 8.0000e-05\n",
      "Epoch 99/200\n",
      " 19/105 [====>.........................] - ETA: 9s - loss: 0.0806"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-4ed10e28428b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1477\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1479\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m   @deprecation.deprecated(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=(len(text_sequences)/BATCH_SIZE),\n",
    "        epochs=200, \n",
    "        verbose=1,\n",
    "        callbacks = callbacks\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\n",
    "    'my_file', overwrite=True, include_optimizer=True, save_format='h5',\n",
    "    signatures=None, options=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('wordtoix.npy', wordtoix) \n",
    "np.save('ixtoword.npy', ixtoword) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -rf /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = tf.keras.models.load_model('../input/language-model/my_file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dummy = ['two','dogs' , 'fighting']\n",
    "X_final = X_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['two', 'dogs', 'fighting', 'between']\n",
      "['two', 'dogs', 'fighting', 'between', 'between', 'the']\n",
      "['two', 'dogs', 'fighting', 'between', 'between', 'the', 'the', 'coachman']\n",
      "['two', 'dogs', 'fighting', 'between', 'between', 'the', 'the', 'coachman', 'coachman', 'the']\n",
      "['two', 'dogs', 'fighting', 'between', 'between', 'the', 'the', 'coachman', 'coachman', 'the', 'the', 'coachman']\n",
      "['dogs', 'fighting', 'between', 'between', 'the', 'the', 'coachman', 'coachman', 'the', 'the', 'coachman', 'coachman', 'after']\n",
      "['fighting', 'between', 'between', 'the', 'the', 'coachman', 'coachman', 'the', 'the', 'coachman', 'coachman', 'after', 'after', 'and']\n",
      "['between', 'between', 'the', 'the', 'coachman', 'coachman', 'the', 'the', 'coachman', 'coachman', 'after', 'after', 'and', 'and', 'those']\n",
      "['between', 'the', 'the', 'coachman', 'coachman', 'the', 'the', 'coachman', 'coachman', 'after', 'after', 'and', 'and', 'those', 'those', 'had']\n",
      "['the', 'the', 'coachman', 'coachman', 'the', 'the', 'coachman', 'coachman', 'after', 'after', 'and', 'and', 'those', 'those', 'had', 'had', 'but']\n",
      "['the', 'coachman', 'coachman', 'the', 'the', 'coachman', 'coachman', 'after', 'after', 'and', 'and', 'those', 'those', 'had', 'had', 'but', 'but', 'it']\n",
      "['coachman', 'coachman', 'the', 'the', 'coachman', 'coachman', 'after', 'after', 'and', 'and', 'those', 'those', 'had', 'had', 'but', 'but', 'it', 'it', 'my']\n",
      "['coachman', 'the', 'the', 'coachman', 'coachman', 'after', 'after', 'and', 'and', 'those', 'those', 'had', 'had', 'but', 'but', 'it', 'it', 'my', 'my', 'face']\n",
      "['the', 'the', 'coachman', 'coachman', 'after', 'after', 'and', 'and', 'those', 'those', 'had', 'had', 'but', 'but', 'it', 'it', 'my', 'my', 'face', 'face', 'but']\n",
      "['the', 'coachman', 'coachman', 'after', 'after', 'and', 'and', 'those', 'those', 'had', 'had', 'but', 'but', 'it', 'it', 'my', 'my', 'face', 'face', 'but', 'but', 'there']\n",
      "['coachman', 'coachman', 'after', 'after', 'and', 'and', 'those', 'those', 'had', 'had', 'but', 'but', 'it', 'it', 'my', 'my', 'face', 'face', 'but', 'but', 'there', 'there', 'were']\n",
      "['coachman', 'after', 'after', 'and', 'and', 'those', 'those', 'had', 'had', 'but', 'but', 'it', 'it', 'my', 'my', 'face', 'face', 'but', 'but', 'there', 'there', 'were', 'were', 'not']\n",
      "['after', 'after', 'and', 'and', 'those', 'those', 'had', 'had', 'but', 'but', 'it', 'it', 'my', 'my', 'face', 'face', 'but', 'but', 'there', 'there', 'were', 'were', 'not', 'not', 'my']\n",
      "['after', 'and', 'and', 'those', 'those', 'had', 'had', 'but', 'but', 'it', 'it', 'my', 'my', 'face', 'face', 'but', 'but', 'there', 'there', 'were', 'were', 'not', 'not', 'my', 'my', 'husband']\n",
      "['and', 'and', 'those', 'those', 'had', 'had', 'but', 'but', 'it', 'it', 'my', 'my', 'face', 'face', 'but', 'but', 'there', 'there', 'were', 'were', 'not', 'not', 'my', 'my', 'husband', 'husband', 'in']\n",
      "['and', 'those', 'those', 'had', 'had', 'but', 'but', 'it', 'it', 'my', 'my', 'face', 'face', 'but', 'but', 'there', 'there', 'were', 'were', 'not', 'not', 'my', 'my', 'husband', 'husband', 'in', 'in', 'my']\n",
      "['those', 'those', 'had', 'had', 'but', 'but', 'it', 'it', 'my', 'my', 'face', 'face', 'but', 'but', 'there', 'there', 'were', 'were', 'not', 'not', 'my', 'my', 'husband', 'husband', 'in', 'in', 'my', 'my', 'heart']\n",
      "['those', 'had', 'had', 'but', 'but', 'it', 'it', 'my', 'my', 'face', 'face', 'but', 'but', 'there', 'there', 'were', 'were', 'not', 'not', 'my', 'my', 'husband', 'husband', 'in', 'in', 'my', 'my', 'heart', 'heart', 'seemed']\n",
      "['had', 'had', 'but', 'but', 'it', 'it', 'my', 'my', 'face', 'face', 'but', 'but', 'there', 'there', 'were', 'were', 'not', 'not', 'my', 'my', 'husband', 'husband', 'in', 'in', 'my', 'my', 'heart', 'heart', 'seemed', 'seemed', 'to']\n",
      "['had', 'but', 'but', 'it', 'it', 'my', 'my', 'face', 'face', 'but', 'but', 'there', 'there', 'were', 'were', 'not', 'not', 'my', 'my', 'husband', 'husband', 'in', 'in', 'my', 'my', 'heart', 'heart', 'seemed', 'seemed', 'to', 'to', 'myself']\n",
      "['but', 'but', 'it', 'it', 'my', 'my', 'face', 'face', 'but', 'but', 'there', 'there', 'were', 'were', 'not', 'not', 'my', 'my', 'husband', 'husband', 'in', 'in', 'my', 'my', 'heart', 'heart', 'seemed', 'seemed', 'to', 'to', 'myself', 'myself', 'to']\n",
      "['but', 'it', 'it', 'my', 'my', 'face', 'face', 'but', 'but', 'there', 'there', 'were', 'were', 'not', 'not', 'my', 'my', 'husband', 'husband', 'in', 'in', 'my', 'my', 'heart', 'heart', 'seemed', 'seemed', 'to', 'to', 'myself', 'myself', 'to', 'to', 'be']\n",
      "['it', 'it', 'my', 'my', 'face', 'face', 'but', 'but', 'there', 'there', 'were', 'were', 'not', 'not', 'my', 'my', 'husband', 'husband', 'in', 'in', 'my', 'my', 'heart', 'heart', 'seemed', 'seemed', 'to', 'to', 'myself', 'myself', 'to', 'to', 'be', 'be', 'and']\n",
      "['it', 'my', 'my', 'face', 'face', 'but', 'but', 'there', 'there', 'were', 'were', 'not', 'not', 'my', 'my', 'husband', 'husband', 'in', 'in', 'my', 'my', 'heart', 'heart', 'seemed', 'seemed', 'to', 'to', 'myself', 'myself', 'to', 'to', 'be', 'be', 'and', 'and', 'whom']\n",
      "['my', 'my', 'face', 'face', 'but', 'but', 'there', 'there', 'were', 'were', 'not', 'not', 'my', 'my', 'husband', 'husband', 'in', 'in', 'my', 'my', 'heart', 'heart', 'seemed', 'seemed', 'to', 'to', 'myself', 'myself', 'to', 'to', 'be', 'be', 'and', 'and', 'whom', 'whom', 'he']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "length = 30\n",
    "for alpha in (range(length)):\n",
    "  \n",
    "  X_gamma = word_to_ix(X_dummy , wordtoix)\n",
    "  X_alpha = np.expand_dims(np.array(X_gamma) , axis = 0)\n",
    "  yhat = model.predict(X_alpha)\n",
    "  yhat = np.argmax(yhat)\n",
    "  word_to_add = ix_to_word([yhat] , ixtoword)\n",
    "  X_final.append(word_to_add[0])\n",
    "  print(X_dummy)\n",
    "  #print(word_to_add[0])\n",
    "  X_dummy.append(word_to_add[0])\n",
    "  if(len(X_dummy)>12):\n",
    "        X_dummy.pop(0)\n",
    "\n",
    "#print(X_dummy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('wordtoix.npy', wordtoix) \n",
    "\n",
    "# Load\n",
    "#ixtoword_copy = np.load('ixtoword.npy',allow_pickle='TRUE').item()\n",
    "#print(ixtoword_copy['boy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_file = open(\"ixtoword.json\", \"r\")\n",
    "ixtoword_copy = a_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ixtoword_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = model.to_json()\n",
    "with open(json_file_path, \"w\") as file:\n",
    "   file.write(json_file)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(h5_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -rf /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
